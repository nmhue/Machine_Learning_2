{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3723d5e5",
   "metadata": {},
   "source": [
    "#### Ex1: Dùng Numpy implement thuật toán dbscan, test thử với dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.05)\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1010e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_core_point(eps,minPts, df, index):\n",
    "    #get points from given index\n",
    "    x, y = df.iloc[index]['X']  ,  df.iloc[index]['Y']\n",
    "    \n",
    "    #check available points within radius\n",
    "    temp =  df[((np.abs(x - df['X']) <= eps) & (np.abs(y - df['Y']) <= eps)) & (df.index != index)]\n",
    "    \n",
    "    #check how many points are present within radius\n",
    "    if len(temp) >= minPts:\n",
    "        #return format (dataframe, is_core, is_border, is_noise)\n",
    "        return (temp.index , True, False, False)\n",
    "    \n",
    "    elif (len(temp) < minPts) and len(temp) > 0:\n",
    "        #return format (dataframe, is_core, is_border, is_noise)\n",
    "        return (temp.index , False, True, False)\n",
    "    \n",
    "    elif len(temp) == 0:\n",
    "        #return format (dataframe, is_core, is_border, is_noise)\n",
    "        return (temp.index , False, False, True)\n",
    "        \n",
    "def cluster_with_stack(eps, minPts, df):\n",
    "    \n",
    "    #initiating cluster number\n",
    "    C = 1\n",
    "    #initiating stacks to maintain\n",
    "    current_stack = set()\n",
    "    unvisited = list(df.index)\n",
    "    clusters = []\n",
    "    \n",
    "    \n",
    "    while (len(unvisited) != 0): #run until all points have been visited\n",
    "\n",
    "        #identifier for first point of a cluster\n",
    "        first_point = True\n",
    "        \n",
    "        #choose a random unvisited point\n",
    "        current_stack.add(random.choice(unvisited))\n",
    "        \n",
    "        while len(current_stack) != 0: #run until a cluster is complete\n",
    "            \n",
    "            #pop current point from stack\n",
    "            curr_idx = current_stack.pop()\n",
    "            \n",
    "            #check if point is core, neighbour or border\n",
    "            neigh_indexes, iscore, isborder, isnoise = check_core_point(eps, minPts, df, curr_idx)\n",
    "            \n",
    "            #dealing with an edge case\n",
    "            if (isborder & first_point):\n",
    "                #for first border point, we label it aand its neighbours as noise \n",
    "                clusters.append((curr_idx, 0))\n",
    "                clusters.extend(list(zip(neigh_indexes,[0 for _ in range(len(neigh_indexes))])))\n",
    "                \n",
    "                #label as visited\n",
    "                unvisited.remove(curr_idx)\n",
    "                unvisited = [e for e in unvisited if e not in neigh_indexes]\n",
    "    \n",
    "                continue\n",
    "                \n",
    "            unvisited.remove(curr_idx) #remove point from unvisited list\n",
    "            \n",
    "            \n",
    "            neigh_indexes = set(neigh_indexes) & set(unvisited) #look at only unvisited points\n",
    "            \n",
    "            if iscore: #if current point is a core\n",
    "                first_point = False\n",
    "                \n",
    "                clusters.append((curr_idx,C)) #assign to a cluster\n",
    "                current_stack.update(neigh_indexes) #add neighbours to a stack\n",
    "\n",
    "            elif isborder: #if current point is a border point\n",
    "                clusters.append((curr_idx,C))\n",
    "                \n",
    "                continue\n",
    "\n",
    "            elif isnoise: #if current point is noise\n",
    "                clusters.append((curr_idx, 0))\n",
    "                \n",
    "                continue\n",
    "                \n",
    "        if not first_point:\n",
    "            #increment cluster number\n",
    "            C+=1\n",
    "        \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.1\n",
    "minPts = 3\n",
    "data = pd.DataFrame(X, columns = [\"X\", \"Y\"] )\n",
    "clustered = cluster_with_stack(eps, minPts, data)\n",
    "\n",
    "idx , cluster = list(zip(*clustered))\n",
    "cluster_df = pd.DataFrame(clustered, columns = [\"idx\", \"cluster\"])\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "for clust in np.unique(cluster):\n",
    "    plt.scatter(X[cluster_df[\"idx\"][cluster_df[\"cluster\"] == clust].values, 0], X[cluster_df[\"idx\"][cluster_df[\"cluster\"] == clust].values, 1], s=10, label=f\"Cluster{clust}\")\n",
    "\n",
    "plt.legend([f\"Cluster {clust}\" for clust in np.unique(cluster)], loc =\"lower right\")\n",
    "plt.title('Clustered Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56ec04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb872c9f",
   "metadata": {},
   "source": [
    "#### Ex2: Ý nghĩa tham số radius, min sample trong thuật toán dbscan? Nếu chỉ số lớn, nhỏ ảnh hưởng thế nào tới thuật toán?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1f782",
   "metadata": {},
   "source": [
    "+ Radius r (eps) là bán kính từ 1 điểm (khoảng cách chỉ định các vùng lân cận) trong đó hai điểm được coi là hàng xóm nếu khoảng cách giữa chúng nhỏ hơn hoặc bằng eps. Nếu r lớn hơn, thì bán kinh cũng sẽ lớn hơn sẽ kéo nhiều điểm về cùng một nhóm và có nhiều nhiễu trong nhóm đó hơn dẫn đến vô nghĩa trong bài toán phân cụm. Nếu radius thấp đi và có thể bị thiếu mất dữ liệu dẫn đến nhiễu và không phân cụm được.\n",
    "+ MinPts là số điểm dữ liệu tối thiểu để xác định một cụm. Số lượng minPts không bao gồm điểm ở tâm. Nếu minPts thấp đi, thì sẽ có nhiều core point hơn nên sẽ nhiễu hơn. Nếu minPts tăng lên, sẽ khó hơn để trở thành 1 core point, nhiều điểm sẽ bị coi là nhiễu, số lượng nhóm phân loại được sẽ ít đi dẫn đến không chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339acc7",
   "metadata": {},
   "source": [
    "#### Ex3: Biến đổi lại và so sánh ba thuật toán: kmean, GMM, dbscan. Khi nào nên sử dụng thuật toán nào? cho ví dụ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05935cf",
   "metadata": {},
   "source": [
    "#### K-means\n",
    "\n",
    "##### Ưu điểm:\n",
    "+ Đơn giản, dễ hiểu, tương đối hiệu quả.\n",
    "+ Các đối tượng tự động gán vào nhóm.\n",
    "+ Thường được tối ưu cục bộ.\n",
    "\n",
    "##### Nhược điểm\n",
    "+ Các thuộc tính không phải số.\n",
    "+ Cần xác định số nhóm (KK) trước.\n",
    "+ Phụ thuộc vào việc chọn các nhóm đầu tiên.\n",
    "+ Gặp vấn đề khi các nhóm có kích thước, mật độ khác nhau hoặc hình dáng không phải hình cầu.\n",
    "+ Nhạy cảm với dữ liệu nhiễu hay outliers : Khi xuất hiện outliers thì thường khiến cho tâm cụm bị chệch và do đó dự báo cụm không còn chuẩn xác\n",
    "\n",
    "=> Trường hợp sử dụng: kích thước cụm đồng đều, hình học phẳng, không quá nhiều cụm.\n",
    "\n",
    "#### GMM\n",
    "\n",
    "##### Ưu điểm\n",
    "+ Xử lý nhiều hình dạng hơn, chủ yếu là các cụm tạo thành hình elip (K-Means chỉ thực sự tốt ở các cụm có dạng gần giống hình cầu)\n",
    "+ Soft assignment: trong k-means 1 điểm chỉ thuộc 1 cluster do k-means là hard assigment. Tuy nhiên, ở trong GMM, 1 điểm có thể thuộc vào nhiều cluster với mức độ khác nhau. Điều này hữu ích trong một số task như một bài báo có thể thuộc nhiều chủ đề,..\n",
    "\n",
    "##### Nhược điểm\n",
    "+ không xác định chính xác được một số cụm có hình dạng khác\n",
    "\n",
    "=> Trường hợp sử dụng: ước tính mật độ và hình học phẳng.\n",
    "\n",
    "#### DBScan\n",
    "\n",
    "##### Ưu điểm\n",
    "+ Tự động loại bỏ được các điểm dữ liệu nhiễu\n",
    "+ Có tốc độ tính toán nhanh.\n",
    "+ Không yêu cầu xác định trước số lượng cụm.\n",
    "+ Hoạt động tốt với các cụm hình dạng tùy ý.\n",
    "+ DBSCAN mạnh mẽ đối với các ngoại lệ và có thể phát hiện các ngoại lệ.\n",
    "\n",
    "##### Nhược điểm\n",
    "+ Không hiệu quả đối với những dữ liệu có phân phối đều khắp nơi.\n",
    "+ Nếu các cụm rất khác nhau về mật độ trong cụm, thì DBSCAN không phù hợp để xác định các cụm.\n",
    "+ Nhạy cảm với các thông số eps và minPts.\n",
    "\n",
    "=> Trường hợp sử dụng: kích thước cụm không đồng đều và hình học không phẳng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48216107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
